{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bd2e32d",
   "metadata": {},
   "source": [
    "# Object Detection Using OpenCV and SSD MobileNet\n",
    "\n",
    "---\n",
    "\n",
    "### **Introduction**\n",
    "Object detection is a crucial task in computer vision, allowing computers to identify and localize objects in images or videos. This project showcases a **real-time object detection system** implemented using **OpenCV** and a pre-trained **MobileNet-SSD** model. The system leverages a lightweight deep neural network architecture to perform accurate object detection on images and live video streams, including webcam feeds.\n",
    "\n",
    "---\n",
    "\n",
    "### **Objectives**\n",
    "1. **Object Detection**: Detect and localize objects in static images and live video streams.\n",
    "2. **Real-Time Performance**: Achieve fast detection with minimal computational overhead.\n",
    "3. **Pre-trained Models**: Utilize pre-trained weights to avoid the need for large-scale training.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Features**\n",
    "- **Supports Images and Videos**: The project can process both static images and real-time video feeds.\n",
    "- **Lightweight Architecture**: Uses the MobileNet-SSD model for efficient object detection.\n",
    "- **Pre-trained on COCO Dataset**: Recognizes 80 classes of objects defined by the COCO dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### **Project Code Explanation**\n",
    "\n",
    "#### **1. Dependencies and Libraries**\n",
    "The project relies on the following:\n",
    "- **OpenCV**: For image processing and visualization.\n",
    "- **Pre-trained MobileNet-SSD**: For object detection.\n",
    "- **COCO Dataset**: Provides class labels for detected objects.\n",
    "\n",
    "#### **2. Object Detection from Images**\n",
    "The `ImgFile()` function processes a single image:\n",
    "- **Load Image**: Reads the image using OpenCV’s `cv2.imread`.\n",
    "- **Load Class Labels**: Reads the `coco.names` file, which contains the 80 object classes.\n",
    "- **Load Model**: Initializes the MobileNet-SSD model using a configuration file (`.pbtxt`) and pre-trained weights (`.pb`).\n",
    "- **Object Detection**: Detects objects using the `detect()` method and visualizes the results by drawing bounding boxes and class labels.\n",
    "\n",
    "#### **3. Real-Time Object Detection**\n",
    "The `Camera()` function processes live video feeds:\n",
    "- **Initialize Webcam**: Captures video frames using OpenCV’s `VideoCapture`.\n",
    "- **Model Setup**: Similar to the image-based detection, loads the MobileNet-SSD model and class labels.\n",
    "- **Continuous Detection**: In a loop, processes each video frame, detects objects, and overlays bounding boxes and labels in real time.\n",
    "\n",
    "---\n",
    "\n",
    "### **Code Walkthrough**\n",
    "\n",
    "#### **Image Detection: `ImgFile()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba2aae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImgFile():\n",
    "   img = cv2.imread('person.png')\n",
    "\n",
    "   classNames = []\n",
    "   classFile = 'coco.names'\n",
    "\n",
    "   with open(classFile, 'rt') as f:\n",
    "      classNames = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "   configPath = 'ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt'\n",
    "   weightpath = 'frozen_inference_graph.pb'\n",
    "\n",
    "   net = cv2.dnn_DetectionModel(weightpath, configPath)\n",
    "   net.setInputSize(320 , 230)\n",
    "   net.setInputScale(1.0 / 127.5)\n",
    "   net.setInputMean((127.5, 127.5, 127.5))\n",
    "   net.setInputSwapRB(True)\n",
    "\n",
    "   classIds, confs, bbox = net.detect(img, confThreshold=0.5)\n",
    "   print(classIds, bbox)\n",
    "\n",
    "   for classId, confidence, box in zip(classIds.flatten(), confs.flatten(), bbox):\n",
    "      cv2.rectangle(img, box, color=(0, 255, 0), thickness=2)\n",
    "      cv2.putText(img, classNames[classId-1], (box[0] + 10, box[1] + 20), \n",
    "                  cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), thickness=2)\n",
    "\n",
    "\n",
    "   cv2.imshow('Output', img)\n",
    "   cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f7a460",
   "metadata": {},
   "source": [
    "#### **Video Detection: `Camera()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acb1e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Camera():\n",
    "   cam = cv2.VideoCapture(0)\n",
    "\n",
    "   cam.set(3, 740)\n",
    "   cam.set(4, 580)\n",
    "\n",
    "   classNames = []\n",
    "   classFile = 'coco.names'\n",
    "\n",
    "   with open(classFile, 'rt') as f:\n",
    "      classNames = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "   configPath = 'ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt'\n",
    "   weightpath = 'frozen_inference_graph.pb'\n",
    "\n",
    "   net = cv2.dnn_DetectionModel(weightpath, configPath)\n",
    "   net.setInputSize(320 , 230)\n",
    "   net.setInputScale(1.0 / 127.5)\n",
    "   net.setInputMean((127.5, 127.5, 127.5))\n",
    "   net.setInputSwapRB(True)\n",
    "\n",
    "   while True:\n",
    "      success, img = cam.read()\n",
    "      classIds, confs, bbox = net.detect(img, confThreshold=0.5)\n",
    "      print(classIds, bbox)\n",
    "\n",
    "      if len(classIds) !=0:\n",
    "         for classId, confidence, box in zip(classIds.flatten(), confs.flatten(), bbox):\n",
    "            cv2.rectangle(img, box, color=(0, 255, 0), thickness=2)\n",
    "            cv2.putText(img, classNames[classId-1], (box[0] + 10, box[1] + 20), \n",
    "                        cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), thickness=2)\n",
    "\n",
    "\n",
    "      cv2.imshow('Output', img)\n",
    "      cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c2c779",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **Execution**\n",
    "- To process an image: uncomment `ImgFile()` in the script.\n",
    "- To process video or webcam feed: uncomment `Camera()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db35ba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImgFile()\n",
    "# Camera()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56895dc2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **Results**\n",
    "1. **Image Detection**:\n",
    "   - The program identifies and labels objects in static images.\n",
    "   - Bounding boxes and class labels are displayed for each detected object.\n",
    "   \n",
    "2. **Video Detection**:\n",
    "   - Objects in live video streams are detected in real time.\n",
    "   - Results update dynamically as the video feed changes.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "This project demonstrates a practical implementation of real-time object detection using pre-trained deep learning models. The lightweight **MobileNet-SSD** model ensures quick processing suitable for real-time applications. The system can be extended for custom datasets or fine-tuned to specific use cases, such as surveillance, autonomous vehicles, or retail analytics.\n",
    "\n",
    "---\n",
    "\n",
    "### **Future Work**\n",
    "1. **Custom Object Detection**: Fine-tune the model for domain-specific applications.\n",
    "2. **Improved Performance**: Optimize for faster processing on low-end hardware.\n",
    "3. **Deployment**: Package the project as a web or mobile app for end-users.\n",
    "4. **Additional Features**: Incorporate object tracking for video streams.\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
